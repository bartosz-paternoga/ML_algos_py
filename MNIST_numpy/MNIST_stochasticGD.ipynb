{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train[0] \n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "y_train[0] \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",\"\\n\", x_train[0])\n",
    "print(\"y_train\",\"\\n\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images \n",
      " (1000, 784)\n",
      "labels[0] value \n",
      " 5\n",
      "labels.shape \n",
      " (1000,)\n",
      "one_hot_labels.shape \n",
      " (1000, 10)\n",
      "one_hot_labels \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "print(\"images\",\"\\n\", images.shape)\n",
    "print(\"labels[0] value\",\"\\n\", labels[0])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "\n",
    "print(\"labels.shape\",\"\\n\", labels.shape)\n",
    "print(\"one_hot_labels.shape\",\"\\n\", one_hot_labels.shape)\n",
    "\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "\n",
    "labels = one_hot_labels\n",
    "print(\"one_hot_labels\",\"\\n\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_0_1.shape \n",
      " (784, 40)\n",
      "weights_0_1 \n",
      " [[-0.0165956   0.0440649  -0.09997713 ...  0.06692513 -0.09634234\n",
      "   0.05002886]\n",
      " [ 0.09777222  0.04963313 -0.0439112  ... -0.03044683  0.05016242\n",
      "   0.0451996 ]\n",
      " [ 0.07666122  0.02473444  0.05018849 ...  0.08460491  0.04230495\n",
      "  -0.07514581]\n",
      " ...\n",
      " [ 0.01278792 -0.09335507  0.07751823 ...  0.09348249 -0.06255046\n",
      "  -0.0724688 ]\n",
      " [ 0.02621576  0.03130522  0.0567295  ... -0.02118333 -0.06391994\n",
      "   0.07874013]\n",
      " [-0.01947632  0.07673669  0.09756995 ...  0.03445804  0.03748222\n",
      "   0.05496171]]\n",
      "weights_1_2.shape \n",
      " (40, 10)\n",
      "weights_1_2 \n",
      " [[-0.0129138  -0.09765532 -0.03772776  0.04511556  0.03713697  0.0539454\n",
      "   0.03387069  0.05517784  0.03646633 -0.08577301]\n",
      " [-0.04615044 -0.08412712  0.05727073  0.03236628  0.00431314  0.02723871\n",
      "   0.04244115 -0.08035061  0.08789485  0.07374967]\n",
      " [ 0.06340531  0.02385217  0.03497944 -0.00299381  0.04807886  0.019268\n",
      "  -0.03119899 -0.07911008  0.01948379 -0.07104769]\n",
      " [ 0.04609973 -0.08527007 -0.00049257  0.06213223 -0.00882449  0.02190663\n",
      "   0.00279074 -0.01196093 -0.05897179  0.0380231 ]\n",
      " [ 0.03995727  0.09438777 -0.04941219 -0.06811581  0.08975204 -0.04915065\n",
      "  -0.0589373   0.09286435  0.01913992  0.00151717]\n",
      " [-0.06249569  0.02431781  0.04812758 -0.08272808 -0.09998554  0.08051142\n",
      "  -0.06638741 -0.09587491 -0.02000817  0.08689589]\n",
      " [ 0.04585729 -0.08622437  0.04500896 -0.07731963 -0.01121526  0.00251785\n",
      "  -0.02307935 -0.09354825 -0.01339034 -0.05824546]\n",
      " [ 0.07997581  0.04464193  0.00901764 -0.09651296 -0.02375744  0.03279073\n",
      "   0.03557214 -0.05965705 -0.05432714 -0.06222089]\n",
      " [ 0.00092071 -0.07276374 -0.08528315 -0.0572379  -0.00612172 -0.03849962\n",
      "  -0.03769814 -0.05978221 -0.09560743 -0.02700072]\n",
      " [-0.03329147 -0.03877572 -0.0294139   0.06807041 -0.00566807 -0.09312654\n",
      "   0.05368642  0.01768586  0.03197487  0.04766777]\n",
      " [-0.09113742 -0.06064603  0.03878189  0.00737614 -0.06496585  0.02674432\n",
      "  -0.06018766 -0.04324148 -0.06101923  0.02548564]\n",
      " [ 0.02990459  0.05316793  0.06734011 -0.06273135  0.04123962  0.00591633\n",
      "   0.09834525  0.04449688  0.06438695 -0.05582392]\n",
      " [ 0.04288595 -0.07496776  0.09273844 -0.07601289  0.0148648  -0.06870468\n",
      "   0.04412859 -0.07006673  0.01987681  0.03618584]\n",
      " [-0.04289147  0.07686115 -0.02973791 -0.0336208   0.04663663 -0.03458815\n",
      "  -0.09707484 -0.08754996 -0.09725544  0.08076666]\n",
      " [-0.02580062 -0.09658538 -0.00772714 -0.06835177  0.0396417   0.0049233\n",
      "  -0.05374921 -0.08424795  0.03156013 -0.01055581]\n",
      " [ 0.0829581   0.04728049 -0.00375379 -0.09783033  0.08477977 -0.09325535\n",
      "   0.05328879  0.0988261   0.00083413 -0.04244743]\n",
      " [ 0.09590369  0.04314601  0.00864173  0.01440659  0.01815594  0.08672137\n",
      "  -0.09911992 -0.02911952 -0.06613509  0.09637039]\n",
      " [-0.03223091  0.07500642  0.01465295 -0.08106238  0.0543257  -0.00139804\n",
      "   0.08738836 -0.0334187   0.00980489 -0.0463859 ]\n",
      " [ 0.09363968  0.03159768  0.01553586 -0.0796369   0.06771007 -0.0167501\n",
      "  -0.0383624  -0.03716252  0.0158416  -0.02428124]\n",
      " [ 0.05482504 -0.09421711  0.01535033 -0.00828473 -0.01232196  0.09738451\n",
      "  -0.07304996 -0.08982687 -0.00296237  0.05039233]\n",
      " [ 0.05915231 -0.03179029  0.05681104 -0.06267088 -0.02573055 -0.028775\n",
      "   0.00612768  0.06594597 -0.00102269 -0.02120018]\n",
      " [ 0.03974482  0.00172533  0.06706946  0.04758862 -0.08866602  0.08495147\n",
      "  -0.09769466 -0.04202268 -0.07903425 -0.07692973]\n",
      " [-0.04026142  0.08712755  0.08009274 -0.09377737  0.09647882  0.07853054\n",
      "   0.03123838 -0.01124942 -0.01736773  0.01422159]\n",
      " [ 0.0998158  -0.0698424   0.06243991 -0.02487242 -0.09490582  0.02527284\n",
      "   0.01761334  0.03765043 -0.05655269 -0.07464376]\n",
      " [-0.0427602  -0.06780746  0.02874123 -0.0611666   0.01579404 -0.03747289\n",
      "  -0.0778975  -0.04626774 -0.07121086 -0.03265482]\n",
      " [-0.05151669 -0.01677685 -0.01453927 -0.00482352 -0.07291177 -0.05367189\n",
      "  -0.08550105  0.07662823  0.08932185  0.09056709]\n",
      " [-0.07939773  0.0375836   0.02738048  0.0841153  -0.04121978  0.08795644\n",
      "   0.0087108  -0.07662865  0.00043267 -0.01900109]\n",
      " [ 0.05342352 -0.02979862  0.04612135  0.07522965  0.06012916 -0.03260929\n",
      "  -0.008884   -0.08482819 -0.09363561 -0.04558989]\n",
      " [ 0.04472269 -0.01199166 -0.0730425   0.00779582  0.05676923  0.08399331\n",
      "   0.08564545  0.09135563 -0.00064699 -0.05940068]\n",
      " [-0.07634144 -0.06194828  0.0107106   0.09164581 -0.01992654 -0.07594254\n",
      "   0.04601844 -0.07376363  0.00567586  0.03943954]\n",
      " [ 0.08607165 -0.0001807   0.0797406   0.04328398 -0.02674751  0.0369066\n",
      "  -0.01093766 -0.05250777  0.07376626  0.00917847]\n",
      " [ 0.03584504  0.09243515  0.02065396  0.07671387 -0.00197065 -0.06450581\n",
      "   0.08328546  0.0459936   0.07649433 -0.07688293]\n",
      " [ 0.01800715 -0.0206182   0.08550251 -0.00988655  0.05267247 -0.01814056\n",
      "   0.0017276  -0.07544753  0.0601164   0.04512688]\n",
      " [-0.03041004  0.06814941  0.00291309  0.05540364  0.01892913  0.06572452\n",
      "   0.04728202  0.00996019  0.08830984  0.09220411]\n",
      " [ 0.01858045 -0.07099698  0.00256906 -0.07264278 -0.04094707  0.0740886\n",
      "  -0.04182058 -0.06316414 -0.08611492 -0.07915106]\n",
      " [-0.04809014  0.05860162 -0.06346889  0.06337482 -0.03156664  0.02559812\n",
      "  -0.0623781  -0.06906175 -0.00439504 -0.01467699]\n",
      " [-0.09659778  0.06236901 -0.0687063  -0.04799369 -0.02245889 -0.02253336\n",
      "  -0.03717397  0.08403321 -0.09332832  0.04953149]\n",
      " [ 0.02141647 -0.0908912   0.0706811   0.08588566 -0.05206652  0.05791862\n",
      "   0.00904549 -0.07937532 -0.08401241  0.02053458]\n",
      " [-0.00966948  0.06351153  0.08175382 -0.07071402  0.03747366 -0.04186441\n",
      "  -0.00114258  0.00524406  0.07480413 -0.01778605]\n",
      " [-0.06710872 -0.05041535  0.05366403 -0.07421658 -0.06444019  0.0676257\n",
      "   0.06084457  0.0615959  -0.02703143 -0.02455863]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x # returns x if x > 0, return 0 otherwise\n",
    "relu2deriv = lambda x: x>=0 # returns 1 for input > 0, return 0 otherwise\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "print(\"weights_0_1.shape\",\"\\n\", weights_0_1.shape)\n",
    "print(\"weights_0_1\",\"\\n\", weights_0_1)\n",
    "print(\"weights_1_2.shape\",\"\\n\", weights_1_2.shape)\n",
    "print(\"weights_1_2\",\"\\n\", weights_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.584 Test-Acc:0.6581 Train-Err:0.607 Train-Acc:0.659\n",
      "I:10 Test-Err:0.558 Test-Acc:0.7238 Train-Err:0.529 Train-Acc:0.712\n",
      "I:20 Test-Err:0.507 Test-Acc:0.7374 Train-Err:0.499 Train-Acc:0.713\n",
      "I:30 Test-Err:0.489 Test-Acc:0.7531 Train-Err:0.469 Train-Acc:0.774\n",
      "I:40 Test-Err:0.462 Test-Acc:0.7682 Train-Err:0.458 Train-Acc:0.771\n",
      "I:50 Test-Err:0.444 Test-Acc:0.7723 Train-Err:0.419 Train-Acc:0.788\n",
      "I:60 Test-Err:0.451 Test-Acc:0.7797 Train-Err:0.432 Train-Acc:0.791\n",
      "I:70 Test-Err:0.449 Test-Acc:0.7799 Train-Err:0.427 Train-Acc:0.798\n",
      "I:80 Test-Err:0.438 Test-Acc:0.7864 Train-Err:0.414 Train-Acc:0.813\n",
      "I:90 Test-Err:0.439 Test-Acc:0.7865 Train-Err:0.421 Train-Acc:0.808\n",
      "I:100 Test-Err:0.450 Test-Acc:0.7763 Train-Err:0.412 Train-Acc:0.818\n",
      "I:110 Test-Err:0.436 Test-Acc:0.7823 Train-Err:0.402 Train-Acc:0.825\n",
      "I:120 Test-Err:0.440 Test-Acc:0.776 Train-Err:0.416 Train-Acc:0.817\n",
      "I:130 Test-Err:0.434 Test-Acc:0.7818 Train-Err:0.409 Train-Acc:0.804\n",
      "I:140 Test-Err:0.452 Test-Acc:0.7798 Train-Err:0.401 Train-Acc:0.836\n",
      "I:150 Test-Err:0.440 Test-Acc:0.7978 Train-Err:0.407 Train-Acc:0.811\n",
      "I:160 Test-Err:0.459 Test-Acc:0.7706 Train-Err:0.413 Train-Acc:0.812\n",
      "I:170 Test-Err:0.450 Test-Acc:0.774 Train-Err:0.392 Train-Acc:0.822\n",
      "I:180 Test-Err:0.451 Test-Acc:0.7677 Train-Err:0.407 Train-Acc:0.822\n",
      "I:190 Test-Err:0.448 Test-Acc:0.7756 Train-Err:0.404 Train-Acc:0.817\n",
      "I:200 Test-Err:0.431 Test-Acc:0.7769 Train-Err:0.390 Train-Acc:0.841\n",
      "I:210 Test-Err:0.447 Test-Acc:0.7799 Train-Err:0.413 Train-Acc:0.822\n",
      "I:220 Test-Err:0.446 Test-Acc:0.7796 Train-Err:0.381 Train-Acc:0.843\n",
      "I:230 Test-Err:0.443 Test-Acc:0.7724 Train-Err:0.402 Train-Acc:0.818\n",
      "I:240 Test-Err:0.444 Test-Acc:0.7766 Train-Err:0.388 Train-Acc:0.835\n",
      "I:250 Test-Err:0.439 Test-Acc:0.7806 Train-Err:0.387 Train-Acc:0.835\n",
      "I:260 Test-Err:0.429 Test-Acc:0.7776 Train-Err:0.387 Train-Acc:0.829\n",
      "I:270 Test-Err:0.441 Test-Acc:0.7803 Train-Err:0.386 Train-Acc:0.832\n",
      "I:280 Test-Err:0.428 Test-Acc:0.7856 Train-Err:0.377 Train-Acc:0.845\n",
      "I:290 Test-Err:0.445 Test-Acc:0.7845 Train-Err:0.364 Train-Acc:0.851\n",
      "I:300 Test-Err:0.458 Test-Acc:0.7742 Train-Err:0.381 Train-Acc:0.848\n",
      "I:310 Test-Err:0.454 Test-Acc:0.785 Train-Err:0.379 Train-Acc:0.856\n",
      "I:320 Test-Err:0.442 Test-Acc:0.7787 Train-Err:0.364 Train-Acc:0.85\n",
      "I:330 Test-Err:0.437 Test-Acc:0.7879 Train-Err:0.366 Train-Acc:0.85\n",
      "I:340 Test-Err:0.440 Test-Acc:0.7781 Train-Err:0.375 Train-Acc:0.841"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0,0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if(j%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                         \"I:\" + str(j) + \\\n",
    "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
    "                         \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
    "                         \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
