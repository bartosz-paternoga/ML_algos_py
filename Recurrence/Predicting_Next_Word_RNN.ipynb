{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TWvhl5uAx6lr",
        "colab_type": "code",
        "outputId": "f97442b0-cc86-4971-babe-b154b846db4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yloj8NxbyJcb",
        "colab_type": "code",
        "outputId": "b984d905-903b-487b-e884-250914925632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys,random,math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "f = open('gdrive/My Drive/Grokking/tasksv11/en/qa1_single-supporting-fact_train.txt','r')\n",
        "raw = f.readlines()     #len(raw): 3000; raw[:3] ['1 Mary moved to the bathroom.\\n', '2 John went to the hallway.\\n', '3 Where is Mary? \\tbathroom\\t1\\n']\n",
        "f.close()\n",
        "\n",
        "tokens = list()\n",
        "for line in raw[0:1000]:\n",
        "    tokens.append(line.lower().replace(\"\\n\",\"\").split(\" \")[1:])\n",
        "\n",
        "print(len(tokens),tokens[0:3])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 [['mary', 'moved', 'to', 'the', 'bathroom.'], ['john', 'went', 'to', 'the', 'hallway.'], ['where', 'is', 'mary?', '\\tbathroom\\t1']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JSYrGh0eXEa0",
        "colab_type": "code",
        "outputId": "99f4eca9-e2f4-46c2-ea05-b279e04c5eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for sent in tokens:\n",
        "    for word in sent:\n",
        "        vocab.add(word)\n",
        "\n",
        "vocab = list(vocab) #vocab len: 82\n",
        "print(\"sent len:\",len(sent),\"; sent:\",sent)\n",
        "\n",
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word]=i  \n",
        "    \n",
        "def words2indices(sentence):\n",
        "    idx = list()\n",
        "    for word in sentence:\n",
        "        idx.append(word2index[word])\n",
        "    return idx\n",
        "\n",
        "  \n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sent len: 5 ; sent: ['sandra', 'went', 'to', 'the', 'garden.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JOcvo3nyagk9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "embed_size = 10\n",
        "\n",
        "# word embeddings\n",
        "embed = (np.random.rand(len(vocab),embed_size) - 0.5) * 0.1           #embed.shape: (82, 10)\n",
        "\n",
        "# embedding -> embedding (initially the identity matrix)\n",
        "recurrent = np.eye(embed_size)                                        #recurrent.shape: (10, 10)\n",
        "\n",
        "# sentence embedding for empty sentence\n",
        "start = np.zeros(embed_size)\n",
        "\n",
        "# embedding -> output weights\n",
        "decoder = (np.random.rand(embed_size, len(vocab)) - 0.5) * 0.1        #decoder.shape: (10, 82)\n",
        "\n",
        "# one hot lookups (for loss function)\n",
        "one_hot = np.eye(len(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30YXC8M6bsSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(sent):\n",
        "    \n",
        "    layers = list()\n",
        "    layer = {}\n",
        "    layer['hidden'] = start\n",
        "    layers.append(layer)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # forward propagate\n",
        "    preds = list()\n",
        "    for target_i in range(len(sent)):\n",
        "        layer = {} \n",
        "        # try to predict the next term\n",
        "        layer['pred'] = softmax(layers[-1]['hidden'].dot(decoder))    #layer['pred']).shape: (82,)\n",
        "\n",
        "        loss += -np.log(layer['pred'][sent[target_i]])\n",
        "                      \n",
        "        # generate the next hidden state\n",
        "        layer['hidden'] = layers[-1]['hidden'].dot(recurrent) + embed[sent[target_i]]  #layer['hidden'].shape: (10,)\n",
        "        layers.append(layer)\n",
        "        \n",
        "    return layers, loss\n",
        "  \n",
        "#a = [10, 5,20, 81]\n",
        "#predict(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebmwwJ_ot8hy",
        "colab_type": "code",
        "outputId": "bd9bfebb-4387-4012-eafb-6fc764bc616c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "# forward\n",
        "for iter in range(30000):\n",
        "    alpha = 0.001\n",
        "    sent = words2indices(tokens[iter%len(tokens)][1:])   # eg tokens ['moved', 'to', 'the', 'bathroom.'] | eg sent [7, 21, 29, 34]\n",
        "    layers,loss = predict(sent) \n",
        "\n",
        "    # back propagate\n",
        "    for layer_idx in reversed(range(len(layers))):       # eg len(layers): 5       \n",
        "        layer = layers[layer_idx]\n",
        "        target = sent[layer_idx-1]\n",
        "\n",
        "        if(layer_idx > 0):  # if not the first layer\n",
        "            layer['output_delta'] = layer['pred'] - one_hot[target]\n",
        "            new_hidden_delta = layer['output_delta'].dot(decoder.transpose())\n",
        "\n",
        "            # if the last layer - don't pull from a later one becasue it doesn't exist\n",
        "            if(layer_idx == len(layers)-1):\n",
        "                layer['hidden_delta'] = new_hidden_delta\n",
        "            else:\n",
        "                layer['hidden_delta'] = new_hidden_delta + layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
        "        else: # if the first layer\n",
        "            layer['hidden_delta'] = layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
        "\n",
        "\n",
        "\n",
        "    # update weights\n",
        "    start -= layers[0]['hidden_delta'] * alpha / float(len(sent))\n",
        "    for layer_idx,layer in enumerate(layers[1:]):\n",
        "        \n",
        "        decoder -= np.outer(layers[layer_idx]['hidden'], layer['output_delta']) * alpha / float(len(sent))\n",
        "        \n",
        "        embed_idx = sent[layer_idx]\n",
        "        embed[embed_idx] -= layers[layer_idx]['hidden_delta'] * alpha / float(len(sent))\n",
        "        recurrent -= np.outer(layers[layer_idx]['hidden'], layer['hidden_delta']) * alpha / float(len(sent))\n",
        "        \n",
        "    if(iter % 1000 == 0):\n",
        "        print(\"Perplexity:\" + str(np.exp(loss/len(sent))))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity:82.17873506062428\n",
            "Perplexity:82.02226933139343\n",
            "Perplexity:81.89515309084378\n",
            "Perplexity:81.7608584680317\n",
            "Perplexity:81.5751884395345\n",
            "Perplexity:81.26312475414024\n",
            "Perplexity:80.66967250015341\n",
            "Perplexity:79.42072058736662\n",
            "Perplexity:76.38544996500065\n",
            "Perplexity:66.24425744816017\n",
            "Perplexity:32.892724125499505\n",
            "Perplexity:21.224577857741803\n",
            "Perplexity:19.145125610597926\n",
            "Perplexity:17.59763813921389\n",
            "Perplexity:15.453741629316943\n",
            "Perplexity:12.368946607211964\n",
            "Perplexity:9.152429960913144\n",
            "Perplexity:7.262729889619236\n",
            "Perplexity:6.235250493935901\n",
            "Perplexity:5.574673900592536\n",
            "Perplexity:5.1422952014435594\n",
            "Perplexity:4.888386591690299\n",
            "Perplexity:4.737186714527934\n",
            "Perplexity:4.641349679783937\n",
            "Perplexity:4.578618433071957\n",
            "Perplexity:4.523228090459675\n",
            "Perplexity:4.453715425442932\n",
            "Perplexity:4.364217492381606\n",
            "Perplexity:4.258190967825188\n",
            "Perplexity:4.139872979689222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d3cYSI61Td_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "729beaf6-c9d2-4225-ce22-bc94eb444f29"
      },
      "cell_type": "code",
      "source": [
        "sent_index = 4\n",
        "\n",
        "l,_ = predict(words2indices(tokens[sent_index]))\n",
        "\n",
        "print(tokens[sent_index])\n",
        "\n",
        "for i,each_layer in enumerate(l[1:-1]):\n",
        "    input = tokens[sent_index][i]\n",
        "    true = tokens[sent_index][i+1]\n",
        "    pred = vocab[each_layer['pred'].argmax()]\n",
        "    print(\"Prev Input:\" + input + (' ' * (12 - len(input))) +\\\n",
        "          \"True:\" + true + (\" \" * (15 - len(true))) + \"Pred:\" + pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sandra', 'moved', 'to', 'the', 'garden.']\n",
            "Prev Input:sandra      True:moved          Pred:is\n",
            "Prev Input:moved       True:to             Pred:to\n",
            "Prev Input:to          True:the            Pred:the\n",
            "Prev Input:the         True:garden.        Pred:bedroom.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}